{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from naml.dataset import Datasets\n",
    "from naml.dataset.nmt import load_nmt\n",
    "datasets = Datasets(\"~/naml-data\")\n",
    "src_words, target_words = load_nmt(datasets, 'fra', 'eng')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "We have a RNN where\n",
    "$$\n",
    "h_t = \\text{RNN}(x_t, h_{t-1})\n",
    "$$\n",
    "The encoder converts its hidden states $h$ to context vectors $c$ from all timesteps\n",
    "$$\n",
    "c = \\text{Encoder}(\\{h_1, h_2, \\ldots, h_T\\})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 4, 16]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naml.modules import torch, nn, optim, F\n",
    "from naml.modules.sequence import Seq2SeqEncoder\n",
    "\n",
    "encoder = Seq2SeqEncoder(10,8,16,2)\n",
    "encoder.eval()\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "H = encoder.begin_state(X.device, batch_size=4)\n",
    "Y, H = encoder(X, H)\n",
    "Y.shape, H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "The decoder is another RNN that takes hidden state $h_{t-1}$, output $y_{t-1}$, and context vector $c$ to produce hidden state $h_t$ and output $y_t$\n",
    "$$\n",
    "h_t = \\text{RNN}(y_{t-1}, h_{t-1}, c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 7, 10]), torch.Size([2, 4, 16]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from naml.modules.sequence import Seq2SeqDecoder\n",
    "\n",
    "encoder = Seq2SeqEncoder(10,8,16,2)\n",
    "encoder.eval()\n",
    "decoder = Seq2SeqDecoder(10,8,16,2)\n",
    "decoder.eval()\n",
    "\n",
    "X = torch.zeros((4, 7), dtype=torch.long)\n",
    "H = encoder.begin_state(X.device, batch_size=4)   \n",
    "\n",
    "Y, H = encoder(X, H)\n",
    "Y, H = decoder(X, H)\n",
    "Y.shape, H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CEL with masking\n",
    "Masking would simply ignore loss at reserved tokens - defined by sequence lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.3026, 2.3026, 2.3026, 2.3026],\n",
      "        [2.3026, 2.3026, 2.3026, 2.3026],\n",
      "        [2.3026, 2.3026, 2.3026, 2.3026]])\n",
      "tensor([[2.3026, 2.3026, 2.3026, 2.3026],\n",
      "        [2.3026, 2.3026, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000]])\n",
      "tensor([2.3026, 1.1513, 0.0000])\n",
      "tensor([2.3026, 1.1513, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "from naml.modules import torch, nn\n",
    "from naml.sequence import zero_one_mask\n",
    "logits = torch.ones((3, 4, 10)) # batch, step, vocab -> logit for index i\n",
    "target = torch.ones((3, 4)).long() # batch, step -> vocab index\n",
    "loss = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "M_l = loss(logits.permute(0, 2, 1), target)\n",
    "print(M_l)\n",
    "lens = torch.tensor([4, 2, 0])\n",
    "mask = zero_one_mask(M_l.shape, lens)\n",
    "M_l = M_l * mask\n",
    "print(M_l)\n",
    "print(M_l.mean(dim = 1))\n",
    "\n",
    "# With naml module\n",
    "from naml.modules.sequence import CELWithLengthMask\n",
    "loss = CELWithLengthMask()\n",
    "M_l = loss(logits, target, lens)\n",
    "print(M_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Seq2SeqDecoder(\u001b[38;5;28mlen\u001b[39m(tgt_vocab), embed_size, num_hiddens, num_layers)\n\u001b[1;32m     40\u001b[0m net \u001b[38;5;241m=\u001b[39m EncoderDecoder(encoder, decoder)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, lr, epochs, src_vocab, tgt_vocab, src_words, tgt_words, batch_size, num_steps)\u001b[0m\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m CELWithLengthMask()\n\u001b[1;32m     14\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;66;03m# Train mode\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m data_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpair_vocab_batch_sample_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_vocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;129m@run_epochs\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_epoch\u001b[39m():\n\u001b[1;32m     18\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/naml/naml/text.py:139\u001b[0m, in \u001b[0;36mpair_vocab_batch_sample_iter\u001b[0;34m(src_vocab, tgt_vocab, src_words, target_words, batch_size, num_steps)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnaml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m seq_partition_sample_1D_sequential_iter\n\u001b[1;32m    138\u001b[0m X, X_len \u001b[38;5;241m=\u001b[39m src_vocab\u001b[38;5;241m.\u001b[39mto_indices_padded(src_words, num_steps)\n\u001b[0;32m--> 139\u001b[0m Y, Y_len \u001b[38;5;241m=\u001b[39m \u001b[43mtgt_vocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_indices_padded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_words\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, x_len, y, y_len \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    141\u001b[0m     seq_partition_sample_1D_sequential_iter(X, batch_size),\n\u001b[1;32m    142\u001b[0m     seq_partition_sample_1D_sequential_iter(X_len, batch_size),\n\u001b[1;32m    143\u001b[0m     seq_partition_sample_1D_sequential_iter(Y, batch_size),\n\u001b[1;32m    144\u001b[0m     seq_partition_sample_1D_sequential_iter(Y_len, batch_size),\n\u001b[1;32m    145\u001b[0m ):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m x, x_len, y, y_len\n",
      "File \u001b[0;32m~/naml/naml/text.py:114\u001b[0m, in \u001b[0;36mVocabulary.to_indices_padded\u001b[0;34m(self, lines, n_steps, pad_token)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_indices_padded\u001b[39m(\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m, lines: List[List[\u001b[38;5;28mstr\u001b[39m]], n_steps: \u001b[38;5;28mint\u001b[39m, pad_token: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    113\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[0;32m--> 114\u001b[0m         [\n\u001b[1;32m    115\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtruncate_pad(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_indices(line), n_steps, pad_token)\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines\n\u001b[1;32m    117\u001b[0m         ]\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     lens \u001b[38;5;241m=\u001b[39m (result \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m[pad_token][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mlong(), lens\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m~/naml/naml/text.py:115\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mto_indices_padded\u001b[39m(\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m, lines: List[List[\u001b[38;5;28mstr\u001b[39m]], n_steps: \u001b[38;5;28mint\u001b[39m, pad_token: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    113\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\n\u001b[1;32m    114\u001b[0m         [\n\u001b[0;32m--> 115\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruncate_pad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines\n\u001b[1;32m    117\u001b[0m         ]\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    119\u001b[0m     lens \u001b[38;5;241m=\u001b[39m (result \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m[pad_token][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mlong(), lens\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m~/naml/naml/text.py:108\u001b[0m, in \u001b[0;36mVocabulary.truncate_pad\u001b[0;34m(self, indices, n_steps, pad_token)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtruncate_pad\u001b[39m(\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m, indices: torch\u001b[38;5;241m.\u001b[39mTensor, n_steps: \u001b[38;5;28mint\u001b[39m, pad_token: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    107\u001b[0m     pad_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m[pad_token][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m)\u001b[49m[:n_steps]\u001b[38;5;241m.\u001b[39mlong()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.10/site-packages/torch/nn/functional.py:5209\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   5202\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   5203\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[1;32m   5204\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   5205\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   5206\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[1;32m   5207\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5208\u001b[0m             )\u001b[38;5;241m.\u001b[39m_replication_pad(\u001b[38;5;28minput\u001b[39m, pad)\n\u001b[0;32m-> 5209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from naml.modules import List\n",
    "from naml.text import Vocabulary, pair_vocab_batch_sample_iter\n",
    "from naml.util import run_epochs, ret_single_loss\n",
    "from naml.modules.sequence import EncoderDecoder\n",
    "def train(\n",
    "        net : EncoderDecoder, lr, epochs, \n",
    "        src_vocab : Vocabulary, tgt_vocab : Vocabulary, \n",
    "        src_words : List[List[str]], tgt_words : List[List[str]],\n",
    "        batch_size: int, num_steps: int\n",
    "    ):\n",
    "    # TODO: Xavier weight init\n",
    "    opt = optim.Adam(net.parameters(), lr=lr) # XXX: Different optimizer?\n",
    "    loss = CELWithLengthMask()\n",
    "    net.train() # Train mode\n",
    "    data_iter = list(pair_vocab_batch_sample_iter(src_vocab, tgt_vocab, src_words, tgt_words,batch_size,num_steps))\n",
    "    @run_epochs(\"Loss\")\n",
    "    def run_epoch():\n",
    "        opt.zero_grad()\n",
    "        ret_loss = ret_single_loss()\n",
    "        for x, x_len, y, y_len in data_iter:\n",
    "            bos = torch.Tensor(tgt_vocab.to_indices([\"<bos>\"] * y.shape[1])).long().reshape(-1,1)\n",
    "            y_in = torch.cat([bos, y[:-1]], 0) # XXX: Can we do this in data_iter instead?\n",
    "            y_hat, _ = net.forward(x, y_in)\n",
    "            l = loss.forward(y_hat, y, y_len)\n",
    "            l.sum().backward()            \n",
    "            # TODO: Grad clipping\n",
    "            opt.step()\n",
    "            ret_loss.update(l.sum().detach())\n",
    "        return ret_loss\n",
    "    run_epoch(epochs)\n",
    "\n",
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.0\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs = 0.005, 250\n",
    "\n",
    "from naml.text import flatten\n",
    "src_vocab, tgt_vocab = Vocabulary(flatten(src_words)), Vocabulary(flatten(target_words))\n",
    "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers)\n",
    "decoder = Seq2SeqDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers)\n",
    "net = EncoderDecoder(encoder, decoder)\n",
    "train(net, lr, num_epochs, src_vocab, tgt_vocab, src_words, target_words, batch_size, num_steps)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
